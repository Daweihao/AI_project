{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T20:43:00.268577Z",
     "start_time": "2019-04-06T20:43:00.258158Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T20:43:01.940100Z",
     "start_time": "2019-04-06T20:43:01.933199Z"
    }
   },
   "outputs": [],
   "source": [
    "def hisEqulColor(img):\n",
    "    ycrcb = cv2.cvtColor(img, cv2.COLOR_BGR2YCR_CB)\n",
    "    channels = cv2.split(ycrcb)\n",
    "    print(len(channels))\n",
    "    cv2.equalizeHist(channels[0], channels[0])\n",
    "    cv2.merge(channels, ycrcb)\n",
    "    cv2.cvtColor(ycrcb, cv2.COLOR_YCR_CB2BGR, img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T23:28:27.743113Z",
     "start_time": "2019-04-06T21:13:44.785910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for num in range(1,196):\n",
    "    nm = str(\"%03d\" % num)\n",
    "    \n",
    "    image = cv2.imread(\"earImageDataset/\"+nm+\"_.jpg\")\n",
    "    image = cv2.resize(image,(756,1008))\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    eq = cv2.equalizeHist(gray)         #灰度图片直方图均衡化\n",
    "    eqc = hisEqulColor(image)\n",
    "    left_ear_cascade = cv2.CascadeClassifier(r'haarcascade_mcs_rightear.xml')\n",
    "    if left_ear_cascade.empty():\n",
    "        raise IOError('Unable to load the left ear cascade classifier xml file')\n",
    "    xx = 1008\n",
    "    yy = 1008\n",
    "    ww = 1008\n",
    "    hh = 1008\n",
    "    for i in range(5):\n",
    "        for j in range(1,100):\n",
    "            left_ear = left_ear_cascade.detectMultiScale(eq,scaleFactor = (1+j/100),minNeighbors = i,minSize = (200,300))\n",
    "            if(len(left_ear) == 1):\n",
    "                for (x,y,w,h) in left_ear:\n",
    "                    if(x<xx and y<yy):\n",
    "                        xx = x\n",
    "                        yy = y\n",
    "                        ww = w\n",
    "                        hh = h\n",
    "    # cv2.rectangle(image, (xx,yy), (xx+ww,yy+hh), (0,255,0), 3)\n",
    "    # cv2.imshow('Ear Detector', cv2.resize(image,(378,504)))\n",
    "    # cv2.imshow('Ear Only', )\n",
    "    cv2.imwrite(\"cropedEar/\" + nm + \"_.jpg\" ,eq[yy:yy+hh,xx:xx+ww])\n",
    "    \n",
    "    \n",
    "    image = cv2.imread(\"earImageDataset/\"+nm+\"_t.jpg\")\n",
    "    image = cv2.resize(image,(756,1008))\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    eq = cv2.equalizeHist(gray)         #灰度图片直方图均衡化\n",
    "    left_ear_cascade = cv2.CascadeClassifier(r'haarcascade_mcs_rightear.xml')\n",
    "    if left_ear_cascade.empty():\n",
    "        raise IOError('Unable to load the left ear cascade classifier xml file')\n",
    "    xx = 1008\n",
    "    yy = 1008\n",
    "    ww = 1008\n",
    "    hh = 1008\n",
    "    for i in range(5):\n",
    "        for j in range(1,100):\n",
    "            left_ear = left_ear_cascade.detectMultiScale(eq,scaleFactor = (1+j/100),minNeighbors = i,minSize = (200,300))\n",
    "            if(len(left_ear) == 1):\n",
    "                for (x,y,w,h) in left_ear:\n",
    "                    if(x<xx and y<yy):\n",
    "                        xx = x\n",
    "                        yy = y\n",
    "                        ww = w\n",
    "                        hh = h\n",
    "    # cv2.rectangle(image, (xx,yy), (xx+ww,yy+hh), (0,255,0), 3)\n",
    "    # cv2.imshow('Ear Detector', cv2.resize(image,(378,504)))\n",
    "    # cv2.imshow('Ear Only', )\n",
    "    \n",
    "    cv2.imwrite(\"cropedEar/\" + nm + \"_t.jpg\" ,eq[yy:yy+hh,xx:xx+ww])\n",
    "\n",
    "    image = cv2.imread(\"earImageDataset/\"+nm+\"_d.jpg\")\n",
    "    image = cv2.resize(image,(756,1008))\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    eq = cv2.equalizeHist(gray)         #灰度图片直方图均衡化\n",
    "    left_ear_cascade = cv2.CascadeClassifier(r'haarcascade_mcs_rightear.xml')\n",
    "    if left_ear_cascade.empty():\n",
    "        raise IOError('Unable to load the left ear cascade classifier xml file')\n",
    "    xx = 1008\n",
    "    yy = 1008\n",
    "    ww = 1008\n",
    "    hh = 1008\n",
    "    for i in range(5):\n",
    "        for j in range(1,100):\n",
    "            left_ear = left_ear_cascade.detectMultiScale(eq,scaleFactor = (1+j/100),minNeighbors = i,minSize = (200,300))\n",
    "            if(len(left_ear) == 1):\n",
    "                for (x,y,w,h) in left_ear:\n",
    "                    if(x<xx and y<yy):\n",
    "                        xx = x\n",
    "                        yy = y\n",
    "                        ww = w\n",
    "                        hh = h\n",
    "    # cv2.rectangle(image, (xx,yy), (xx+ww,yy+hh), (0,255,0), 3)\n",
    "    # cv2.imshow('Ear Detector', cv2.resize(image,(378,504)))\n",
    "    # cv2.imshow('Ear Only', )\n",
    "    cv2.imwrite(\"cropedEar/\" + nm + \"_d.jpg\" ,eq[yy:yy+hh,xx:xx+ww])\n",
    "    \n",
    "    image = cv2.imread(\"earImageDataset/\"+nm+\"_dt.jpg\")\n",
    "    image = cv2.resize(image,(756,1008))\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    eq = cv2.equalizeHist(gray)         #灰度图片直方图均衡化\n",
    "    left_ear_cascade = cv2.CascadeClassifier(r'haarcascade_mcs_rightear.xml')\n",
    "    if left_ear_cascade.empty():\n",
    "        raise IOError('Unable to load the left ear cascade classifier xml file')\n",
    "    xx = 1008\n",
    "    yy = 1008\n",
    "    ww = 1008\n",
    "    hh = 1008\n",
    "    for i in range(5):\n",
    "        for j in range(1,100):\n",
    "            left_ear = left_ear_cascade.detectMultiScale(eq,scaleFactor = (1+j/100),minNeighbors = i,minSize = (200,300))\n",
    "            if(len(left_ear) == 1):\n",
    "                for (x,y,w,h) in left_ear:\n",
    "                    if(x<xx and y<yy):\n",
    "                        xx = x\n",
    "                        yy = y\n",
    "                        ww = w\n",
    "                        hh = h\n",
    "    # cv2.rectangle(image, (xx,yy), (xx+ww,yy+hh), (0,255,0), 3)\n",
    "    # cv2.imshow('Ear Detector', cv2.resize(image,(378,504)))\n",
    "    # cv2.imshow('Ear Only', )\n",
    "    cv2.imwrite(\"cropedEar/\" + nm + \"_dt.jpg\" ,eq[yy:yy+hh,xx:xx+ww])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T21:08:13.101533Z",
     "start_time": "2019-04-06T21:08:12.270137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1008, 756, 3)\n",
      "3\n",
      "(1008, 756, 3)\n",
      "[[[158 109 101]\n",
      "  [158 109 101]\n",
      "  [158 109 101]\n",
      "  ...\n",
      "  [112  85  89]\n",
      "  [112  85  89]\n",
      "  [ 92  65  69]]\n",
      "\n",
      " [[158 109 101]\n",
      "  [154 105  97]\n",
      "  [154 105  97]\n",
      "  ...\n",
      "  [107  80  84]\n",
      "  [107  80  84]\n",
      "  [117  90  94]]\n",
      "\n",
      " [[151 102  94]\n",
      "  [154 105  97]\n",
      "  [154 105  97]\n",
      "  ...\n",
      "  [116  89  93]\n",
      "  [100  73  77]\n",
      "  [112  85  89]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[152 119 116]\n",
      "  [152 119 116]\n",
      "  [152 119 116]\n",
      "  ...\n",
      "  [ 26  10   4]\n",
      "  [ 26  10   4]\n",
      "  [ 26  10   4]]\n",
      "\n",
      " [[152 119 116]\n",
      "  [152 119 116]\n",
      "  [152 119 116]\n",
      "  ...\n",
      "  [ 26  10   4]\n",
      "  [ 26  10   4]\n",
      "  [ 26  10   4]]\n",
      "\n",
      " [[156 123 120]\n",
      "  [138 105 102]\n",
      "  [166 133 130]\n",
      "  ...\n",
      "  [ 26  10   4]\n",
      "  [ 26  10   4]\n",
      "  [ 36  20  14]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread(\"earImageDataset/\"+str(192)+\"_dt.jpg\")\n",
    "image = cv2.resize(image,(756,1008))\n",
    "print(image.shape)\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "eq = cv2.equalizeHist(gray)         #灰度图片直方图均衡化\n",
    "eqc = hisEqulColor(image)\n",
    "left_ear_cascade = cv2.CascadeClassifier(r'haarcascade_mcs_rightear.xml')\n",
    "if left_ear_cascade.empty():\n",
    "    raise IOError('Unable to load the left ear cascade classifier xml file')\n",
    "xx = 1008\n",
    "yy = 1008\n",
    "ww = 1008\n",
    "hh = 1008\n",
    "for i in range(5):\n",
    "    for j in range(1,100):\n",
    "        left_ear = left_ear_cascade.detectMultiScale(eq,scaleFactor = (1+j/100),minNeighbors = i,minSize = (200,300))\n",
    "        if(len(left_ear) == 1):\n",
    "            for (x,y,w,h) in left_ear:\n",
    "                if(x<xx and y<yy):\n",
    "                    xx = x\n",
    "                    yy = y\n",
    "                    ww = w\n",
    "                    hh = h\n",
    "# cv2.rectangle(image, (xx,yy), (xx+ww,yy+hh), (0,255,0), 3)\n",
    "# cv2.imshow('Ear Detector', cv2.resize(image,(378,504)))\n",
    "# cv2.imshow('Ear Only', )\n",
    "print(eqc.shape)\n",
    "croped = image[yy:yy+hh,xx:xx+ww,:]\n",
    "print(croped)\n",
    "croped = cv2.resize(croped,(256,256))\n",
    "cv2.imwrite(\"cropedEar/\" + nm + \"_dt.jpg\" ,croped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
